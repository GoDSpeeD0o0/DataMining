{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\paras\\anaconda3\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\paras\\anaconda3\\lib\\site-packages (from pandas) (2.1.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\paras\\anaconda3\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\paras\\anaconda3\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\paras\\anaconda3\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\paras\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: numpy in c:\\users\\paras\\anaconda3\\lib\\site-packages (2.1.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\paras\\anaconda3\\lib\\site-packages (1.6.1)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\paras\\anaconda3\\lib\\site-packages (from scikit-learn) (2.1.3)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\paras\\anaconda3\\lib\\site-packages (from scikit-learn) (1.15.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\paras\\anaconda3\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\paras\\anaconda3\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas\n",
    "%pip install numpy\n",
    "%pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('test.csv')\n",
    "combine = [train_df, test_df]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_df = train_df.drop(['Ticket', 'Cabin'], axis=1)\n",
    "test_df = test_df.drop(['Ticket', 'Cabin'], axis=1)\n",
    "combine = [train_df, test_df]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for dataset in combine:\n",
    "    dataset['Title'] = dataset.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for dataset in combine:\n",
    "    dataset['Title'] = dataset['Title'].replace(['Lady', 'Countess','Capt', 'Col', 'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n",
    "    dataset['Title'] = dataset['Title'].replace('Mlle', 'Miss')\n",
    "    dataset['Title'] = dataset['Title'].replace('Ms', 'Miss')\n",
    "    dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "title_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5}\n",
    "for dataset in combine:\n",
    "    dataset['Title'] = dataset['Title'].map(title_mapping)\n",
    "    dataset['Title'] = dataset['Title'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_df = train_df.drop(['Name', 'PassengerId'], axis=1)\n",
    "test_df = test_df.drop(['Name'], axis=1)\n",
    "combine = [train_df, test_df]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for dataset in combine:\n",
    "    dataset['Sex'] = dataset['Sex'].map( {'female': 1, 'male': 0} ).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "guess_ages = np.zeros((2,3))\n",
    "for dataset in combine:\n",
    "    for i in range(0, 2):\n",
    "        for j in range(0, 3):\n",
    "            guess_df = dataset[(dataset['Sex'] == i) & (dataset['Pclass'] == j+1)]['Age'].dropna()\n",
    "            age_guess = guess_df.median()\n",
    "            guess_ages[i,j] = int( age_guess/0.5 + 0.5 ) * 0.5\n",
    "    for i in range(0, 2):\n",
    "        for j in range(0, 3):\n",
    "            dataset.loc[ (dataset.Age.isnull()) & (dataset.Sex == i) & (dataset.Pclass == j+1), 'Age'] = guess_ages[i,j]\n",
    "    dataset['Age'] = dataset['Age'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for dataset in combine:\n",
    "    dataset.loc[ dataset['Age'] <= 16, 'Age'] = 0\n",
    "    dataset.loc[(dataset['Age'] > 16) & (dataset['Age'] <= 32), 'Age'] = 1\n",
    "    dataset.loc[(dataset['Age'] > 32) & (dataset['Age'] <= 48), 'Age'] = 2\n",
    "    dataset.loc[(dataset['Age'] > 48) & (dataset['Age'] <= 64), 'Age'] = 3\n",
    "    dataset.loc[ dataset['Age'] > 64, 'Age'] = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for dataset in combine:\n",
    "    dataset['FamilySize'] = dataset['SibSp'] + dataset['Parch'] + 1\n",
    "    dataset['IsAlone'] = 0\n",
    "    dataset.loc[dataset['FamilySize'] == 1, 'IsAlone'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_df = train_df.drop(['Parch', 'SibSp', 'FamilySize'], axis=1)\n",
    "test_df = test_df.drop(['Parch', 'SibSp', 'FamilySize'], axis=1)\n",
    "combine = [train_df, test_df]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for dataset in combine:\n",
    "    dataset['Age*Class'] = dataset.Age * dataset.Pclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "freq_port = train_df.Embarked.dropna().mode()[0]\n",
    "for dataset in combine:\n",
    "    dataset['Embarked'] = dataset['Embarked'].fillna(freq_port)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for dataset in combine:\n",
    "    dataset['Embarked'] = dataset['Embarked'].map( {'S': 0, 'C': 1, 'Q': 2} ).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\paras\\AppData\\Local\\Temp\\ipykernel_55072\\2981760374.py:1: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  test_df['Fare'].fillna(test_df['Fare'].dropna().median(), inplace=True)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test_df['Fare'].fillna(test_df['Fare'].dropna().median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for dataset in combine:\n",
    "    dataset.loc[ dataset['Fare'] <= 7.91, 'Fare'] = 0\n",
    "    dataset.loc[(dataset['Fare'] > 7.91) & (dataset['Fare'] <= 14.454), 'Fare'] = 1\n",
    "    dataset.loc[(dataset['Fare'] > 14.454) & (dataset['Fare'] <= 31), 'Fare']   = 2\n",
    "    dataset.loc[ dataset['Fare'] > 31, 'Fare'] = 3\n",
    "    dataset['Fare'] = dataset['Fare'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train = train_df.drop(\"Survived\", axis=1)\n",
    "Y_train = train_df[\"Survived\"]\n",
    "X_test  = test_df.drop(\"PassengerId\", axis=1).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, Y_train)\n",
    "Y_pred_log = logreg.predict(X_test)\n",
    "acc_log = round(logreg.score(X_train, Y_train) * 100, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "svc = SVC()\n",
    "svc.fit(X_train, Y_train)\n",
    "Y_pred_svc = svc.predict(X_test)\n",
    "acc_svc = round(svc.score(X_train, Y_train) * 100, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "knn = KNeighborsClassifier(n_neighbors = 3)\n",
    "knn.fit(X_train, Y_train)\n",
    "Y_pred_knn = knn.predict(X_test)\n",
    "acc_knn = round(knn.score(X_train, Y_train) * 100, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "gaussian = GaussianNB()\n",
    "gaussian.fit(X_train, Y_train)\n",
    "Y_pred_gaussian = gaussian.predict(X_test)\n",
    "acc_gaussian = round(gaussian.score(X_train, Y_train) * 100, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "perceptron = Perceptron()\n",
    "perceptron.fit(X_train, Y_train)\n",
    "Y_pred_perceptron = perceptron.predict(X_test)\n",
    "acc_perceptron = round(perceptron.score(X_train, Y_train) * 100, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "linear_svc = LinearSVC(dual=False)\n",
    "linear_svc.fit(X_train, Y_train)\n",
    "Y_pred_linear_svc = linear_svc.predict(X_test)\n",
    "acc_linear_svc = round(linear_svc.score(X_train, Y_train) * 100, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sgd = SGDClassifier()\n",
    "sgd.fit(X_train, Y_train)\n",
    "Y_pred_sgd = sgd.predict(X_test)\n",
    "acc_sgd = round(sgd.score(X_train, Y_train) * 100, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "decision_tree = DecisionTreeClassifier()\n",
    "decision_tree.fit(X_train, Y_train)\n",
    "Y_pred_dt = decision_tree.predict(X_test)\n",
    "acc_decision_tree = round(decision_tree.score(X_train, Y_train) * 100, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "random_forest = RandomForestClassifier(n_estimators=100)\n",
    "random_forest.fit(X_train, Y_train)\n",
    "Y_pred_rf = random_forest.predict(X_test)\n",
    "acc_random_forest = round(random_forest.score(X_train, Y_train) * 100, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model Accuracy on Training Data ---\n",
      "                        Model  Score\n",
      "3               Random Forest  86.64\n",
      "8               Decision Tree  86.64\n",
      "0     Support Vector Machines  82.83\n",
      "1                         KNN  82.83\n",
      "2         Logistic Regression  81.37\n",
      "7                  Linear SVC  79.46\n",
      "5                  Perceptron  79.35\n",
      "6  Stochastic Gradient Decent  78.56\n",
      "4                 Naive Bayes  76.88\n"
     ]
    }
   ],
   "source": [
    "\n",
    "models = pd.DataFrame({\n",
    "    'Model': ['Support Vector Machines', 'KNN', 'Logistic Regression', \n",
    "              'Random Forest', 'Naive Bayes', 'Perceptron', \n",
    "              'Stochastic Gradient Decent', 'Linear SVC', \n",
    "              'Decision Tree'],\n",
    "    'Score': [acc_svc, acc_knn, acc_log, \n",
    "              acc_random_forest, acc_gaussian, acc_perceptron, \n",
    "              acc_sgd, acc_linear_svc, acc_decision_tree]})\n",
    "print(\"--- Model Accuracy on Training Data ---\")\n",
    "print(models.sort_values(by='Score', ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\paras\\AppData\\Local\\Temp\\ipykernel_55072\\397878117.py:14: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  combined_df['Embarked'].fillna(combined_df['Embarked'].mode()[0], inplace=True)\n",
      "C:\\Users\\paras\\AppData\\Local\\Temp\\ipykernel_55072\\397878117.py:15: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  combined_df['Fare'].fillna(combined_df['Fare'].median(), inplace=True)\n",
      "C:\\Users\\paras\\AppData\\Local\\Temp\\ipykernel_55072\\397878117.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train[numerical_features] = scaler.fit_transform(X_train[numerical_features])\n",
      "C:\\Users\\paras\\AppData\\Local\\Temp\\ipykernel_55072\\397878117.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[numerical_features] = scaler.transform(X_test[numerical_features])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Improved Model Accuracies on Training Data ---\n",
      "                        Model  Score\n",
      "7               Decision Tree  98.43\n",
      "8               Random Forest  98.43\n",
      "2                         KNN  87.54\n",
      "1     Support Vector Machines  83.16\n",
      "0         Logistic Regression  82.15\n",
      "5                  Linear SVC  81.37\n",
      "6  Stochastic Gradient Decent  80.25\n",
      "3                 Naive Bayes  78.11\n",
      "4                  Perceptron  76.09\n",
      "\n",
      "--- Final Model Accuracy Summary ---\n",
      "The 'Decision Tree' model achieved an accuracy of 98.43% on the training data.\n",
      "The 'Random Forest' model achieved an accuracy of 98.43% on the training data.\n",
      "The 'KNN' model achieved an accuracy of 87.54% on the training data.\n",
      "The 'Support Vector Machines' model achieved an accuracy of 83.16% on the training data.\n",
      "The 'Logistic Regression' model achieved an accuracy of 82.15% on the training data.\n",
      "The 'Linear SVC' model achieved an accuracy of 81.37% on the training data.\n",
      "The 'Stochastic Gradient Decent' model achieved an accuracy of 80.25% on the training data.\n",
      "The 'Naive Bayes' model achieved an accuracy of 78.11% on the training data.\n",
      "The 'Perceptron' model achieved an accuracy of 76.09% on the training data.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "try:\n",
    "    train_df = pd.read_csv('train.csv')\n",
    "    test_df = pd.read_csv('test.csv')\n",
    "    test_passenger_id = test_df['PassengerId']\n",
    "    combined_df = pd.concat([train_df.drop('Survived', axis=1), test_df], ignore_index=True)\n",
    "    combined_df['Title'] = combined_df.Name.str.extract(' ([A-Za-z]+)\\\\.', expand=False)\n",
    "    combined_df['Title'] = combined_df['Title'].replace(['Lady', 'Countess','Capt', 'Col', 'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n",
    "    combined_df['Title'] = combined_df['Title'].replace({'Mlle': 'Miss', 'Ms': 'Miss', 'Mme': 'Mrs'})\n",
    "    combined_df['FamilySize'] = combined_df['SibSp'] + combined_df['Parch'] + 1\n",
    "    combined_df['IsAlone'] = 0\n",
    "    combined_df.loc[combined_df['FamilySize'] == 1, 'IsAlone'] = 1\n",
    "    combined_df.drop(columns=['SibSp', 'Parch', 'FamilySize'], inplace=True)\n",
    "    combined_df['Embarked'].fillna(combined_df['Embarked'].mode()[0], inplace=True)\n",
    "    combined_df['Fare'].fillna(combined_df['Fare'].median(), inplace=True)\n",
    "    combined_df['Age'] = combined_df.groupby(['Pclass', 'Sex'])['Age'].transform(lambda x: x.fillna(x.median()))\n",
    "    categorical_features = ['Embarked', 'Title', 'Sex']\n",
    "    combined_df = pd.get_dummies(combined_df, columns=categorical_features, drop_first=True)\n",
    "    combined_df.drop(columns=['Ticket', 'Cabin', 'Name', 'PassengerId'], inplace=True)\n",
    "    X_train = combined_df.iloc[:len(train_df)]\n",
    "    X_test = combined_df.iloc[len(train_df):]\n",
    "    Y_train = train_df['Survived']\n",
    "    scaler = StandardScaler()\n",
    "    numerical_features = ['Age', 'Fare', 'Pclass']\n",
    "    X_train[numerical_features] = scaler.fit_transform(X_train[numerical_features])\n",
    "    X_test[numerical_features] = scaler.transform(X_test[numerical_features])\n",
    "    X_train.to_csv(\"improved_train.csv\", index=False)\n",
    "    X_test.to_csv(\"improved_test.csv\", index=False)\n",
    "    models_data = []\n",
    "    models_to_run = {\n",
    "        \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
    "        \"Support Vector Machines\": SVC(),\n",
    "        \"KNN\": KNeighborsClassifier(n_neighbors=3),\n",
    "        \"Naive Bayes\": GaussianNB(),\n",
    "        \"Perceptron\": Perceptron(),\n",
    "        \"Linear SVC\": LinearSVC(dual=False, max_iter=2000),\n",
    "        \"Stochastic Gradient Decent\": SGDClassifier(),\n",
    "        \"Decision Tree\": DecisionTreeClassifier(),\n",
    "        \"Random Forest\": RandomForestClassifier(n_estimators=100)\n",
    "    }\n",
    "    for name, model in models_to_run.items():\n",
    "        model.fit(X_train, Y_train)\n",
    "        score = round(model.score(X_train, Y_train) * 100, 2)\n",
    "        models_data.append({'Model': name, 'Score': score})\n",
    "    improved_models_df = pd.DataFrame(models_data)\n",
    "    sorted_models_df = improved_models_df.sort_values(by='Score', ascending=False)\n",
    "    \n",
    "    print(\"--- Improved Model Accuracies on Training Data ---\")\n",
    "    print(sorted_models_df)\n",
    "    print(\"\\n--- Final Model Accuracy Summary ---\")\n",
    "    for index, row in sorted_models_df.iterrows():\n",
    "        print(f\"The '{row['Model']}' model achieved an accuracy of {row['Score']}% on the training data.\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(\"Execution halted. Please upload 'train.csv' and 'test.csv' to proceed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
